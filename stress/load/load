#!/usr/bin/env python
# -*- coding: utf-8 -*-

##***** BEGIN LICENSE BLOCK *****
##Version: MPL 1.1
##
##The contents of this file are subject to the Mozilla Public License Version
##1.1 (the "License"); you may not use this file except in compliance with
##the License. You may obtain a copy of the License at
##http:##www.mozilla.org/MPL/
##
##Software distributed under the License is distributed on an "AS IS" basis,
##WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
##for the specific language governing rights and limitations under the
##License.
##
##The Original Code is the AllegroGraph Java Client interface.
##
##The Original Code was written by Franz Inc.
##Copyright (C) 2009 Franz Inc.  All Rights Reserved.
##
##***** END LICENSE BLOCK *****

"""
Usage: load --help

load will walk the directory (the current directory is default)
or read the file specified for the list of .nt, .owl, and/or
.rdf files and load them using the number of processes (or
4 processes by default). You must use absolute pathnames in
the file list. No blank lines are allowed.

If the environment variable AGRAPH_HOST exists is set to anything other
than localhost, the script accesses the files locally and posts the
contents in the request. Otherwise, it uses server-side loads if on the
same machine as the server.
"""

from __future__ import with_statement
try:
    from multiprocessing import Process
except:
    assert False, \
        'Use Python 2.6 or install http://pypi.python.org/pypi/multiprocessing/'
from Queue import Empty
from datetime import datetime
import locale, os, sys, time, traceback

sys.path.append(os.path.join(os.getcwd(), '../../src2'))

from franz.openrdf.sail import AllegroGraphServer
from franz.openrdf.repository import Repository
from franz.openrdf.query.query import QueryLanguage
from franz.openrdf.vocabulary import XMLSchema

LOCALHOST = 'localhost'
AG_HOST = os.environ.get('AGRAPH_HOST', LOCALHOST)
AG_PORT = int(os.environ.get('AGRAPH_PORT', '10035'))
AG_USER = os.environ.get('AGRAPH_USER', 'test')
AG_PASSWORD = os.environ.get('AGRAPH_PASSWORD', 'xyzzy')
AG_ONSERVER = AG_HOST == LOCALHOST
PROG = sys.argv[0]

class Defaults:
    # The base namespace (for rdf files)
    BASEURI = None;

    # Number of worker processes
    LOADERS = 4

    # The catalog name
    CATALOG = 'tests'

    # The repository name
    REPOSITORY = 'load_test'

    # Whether or not to recurse the directory
    RECURSE = False

    # OPEN OR RENEW the respository
    CREATE = False

    # GRAPH for each file
    GRAPH = None

    # STATUS report frequency
    STATUS = 100

    # The TIMEOUT in seconds for the dedicated session
    TIMEOUT = 7200

# The program options
OPT = Defaults

# The work queue
work = None

def trace(formatter, values=None):
    if values:
        formatter = locale.format_string(formatter, values, grouping=True)
    print formatter
    sys.stdout.flush()

def buggy_version():
    """There is a bug in Python versions <= 2.6.2"""
    return map(int, sys.version.split()[0].split('.')) <= [2, 6, 2]

if buggy_version():
    from multiprocessing.queues import JoinableQueue as BadJoinableQueue
    class JoinableQueue(BadJoinableQueue):
        def put(self, obj, block=True, timeout=None):
            assert not self._closed
            if not self._sem.acquire(block, timeout):
                raise Full

            self._notempty.acquire()
            self._cond.acquire()
            try:
                if self._thread is None:
                    self._start_thread()
                self._buffer.append(obj)
                self._unfinished_tasks.release()
                self._notempty.notify()
            finally:
                self._cond.release()
                self._notempty.release()
else:
    from multiprocessing import JoinableQueue

def connect(access_mode=Repository.OPEN):
    """
    Connect is called to connect to a store.
    """
    server = AllegroGraphServer(AG_HOST, AG_PORT, AG_USER, AG_PASSWORD)
    catalog = server.openCatalog(OPT.CATALOG)
    repository = catalog.getRepository(OPT.REPOSITORY, access_mode)
    repository.initialize()
    return repository.getConnection()

def load_files(proc_num):
    """
    load_files does the work of the child processes.
    """
    conn = connect()
    conn.openSession(True, OPT.TIMEOUT)

    def dequeue():
        try:
            return work.get()
        except Empty:
            return None

    filename = dequeue()

    count = 0
    errors = 0
    while filename:
        if OPT.GRAPH is None:
            context = conn.createLiteral(filename, datatype=XMLSchema.STRING)
        elif OPT.GRAPH == "":
            context = None
        else:
            context = conn.createLiteral(OPT.GRAPH, datatype=XMLSchema.STRING)
        
        if count % OPT.STATUS == 0:
            trace('%s(%d) [%s]: Processed %d files so far...', (
                PROG, proc_num, datetime.now(), count))
            
        try:
            conn.addFile(filename, base=OPT.BASEURI, context=context,
                serverSide=AG_ONSERVER)
            count += 1
        except Exception:
            trace('%s(%d) [%s]: Error processing file %s...', (
                PROG, proc_num, datetime.now(), filename))
            errors += 1
            traceback.print_exc()
        work.task_done()
        filename = dequeue()

    conn.closeSession()
    conn.close()

    trace('%s(%d) [%s]: Process finished, %d files loaded, %d loading errors.',
        (PROG, proc_num, datetime.now(), count, errors))

    work.task_done()

def main(args):
    """
    The parent main process.
    """
    global work

    if not args:
        args = ['.']

    # Get the repository
    trace('%s [%s]: %sing the repository.', (PROG, datetime.now(),
        'Renew' if OPT.CREATE else 'Open'))
    conn = connect(Repository.RENEW if OPT.CREATE else Repository.OPEN)
    triples = conn.size()

    trace('%s [%s]: Processing with %d processes.', (PROG,
        datetime.now(), OPT.LOADERS))

    # Create the work queue
    work = JoinableQueue(maxsize=4000)

    # Start the processes
    for proc_num in range(OPT.LOADERS):
        p = Process(target=load_files, args=(proc_num,))
        p.start()

    # Begin the time on the first file add
    the_time = 0
    count = 0
    extensions = ['.nt', '.ntriples', '.rdf', '.owl']
    bad_paths = []

    for path in args:
        kind = None
        if os.path.exists(path):
            if os.path.isdir(path):
                kind = 'directory'
            else:
                basename, ext = os.path.splitext(path)
                if ext in extensions:
                    kind = 'file'
                else:
                    kind = 'listing'
                
            trace('%s [%s]: Processing %s %s', (PROG,
                datetime.now(), kind, path))
        else:
            trace('%s [%s]: %s not found.', (PROG,
                datetime.now(), path))
            bad_paths.append(path)
            continue

        # Find files to process
        if kind == 'directory':
            for root, dirs, files in os.walk(path, topdown=True):
                for filename in files:
                    basename, ext = os.path.splitext(filename)
                    if ext in extensions:
                        the_time = the_time or time.time()
                        work.put(os.path.abspath(os.path.join(root, filename)))
                        count += 1
                if not OPT.RECURSE:
                    del dirs[:]
        elif kind == 'listing':
            with open(path) as the_file:
                for filename in the_file:
                    # Strip the newline
                    filename = filename[:-1]
                    basename, ext = os.path.splitext(filename)
                    if ext in extensions:
                        the_time = the_time or time.time()
                        work.put(filename)
                        count += 1
        else:
            the_time = the_time or time.time()
            work.put(path)
            count += 1

    # Add OPT.LOADERS empty strings to signal the loaders to die
    for proc_num in range(OPT.LOADERS):
        work.put('')

    # Signal that there is no more work for the queue
    work.close()

    # Wait for all the work to be completed
    work.join()

    # Display the results
    if the_time:
        the_time = time.time() - the_time
    if the_time == 0:
        the_time = 0.0000001
    triples = conn.size() - triples
    conn.close()
    trace('%s [%s]: %d files, %d triples loaded in %s seconds '
        ' (%s triples/second, %s file commits/second).', (PROG, datetime.now(),
        count, triples, the_time, triples/the_time, count/the_time))
    if bad_paths:
        trace('WARNING: These paths were not found:')
        for path in bad_paths:
            trace('\t%s', path)

if __name__ == '__main__':
    from copy import copy
    from optparse import OptionParser, Option, OptionValueError

    locale.setlocale(locale.LC_ALL, '')

    def check_human_timeout(option, opt, value):
        try:
            if value[-1] == 'm':
                value = locale.atof(value[:-1])*60
            elif value[-1] == 's':
                value = locale.atof(value[:-1])
            elif value[-1] == 'h':
                value = locale.atof(value[:-1])*60*60
            else:
                value = locale.atoi(value)

            return int(value)
        except ValueError:
            raise OptionValueError(
                "option %s: invalid human-readable timeout value: %r" % (opt, value))

    class LoadOption(Option):
        TYPES = Option.TYPES + ('human_timeout',)
        TYPE_CHECKER = copy(Option.TYPE_CHECKER)
        TYPE_CHECKER['human_timeout'] = check_human_timeout
    
    usage = ('Usage: %prog [options] [directory_or_file ...]\n\n' 
        'If no directories or files are supplied, load will load\n'
        'files in the current directory. If a file is specified\n'
        'and it ends with .nt, .ntriples, .rdf, or .owl, it will\n'
        'be loaded directly. Files with any other extension (or no\n'
        'extension) are expected to contain a list of files to load.\n\n'
        'Environment Variables Consulted:\n'
        'AGRAPH_HOST [default=localhost]\n'
        'AGRAPH_PORT [default=10035]\n'
        'AGRAPH_USER [default=test]\n'
        'AGRAPH_PASSWORD [default=xyzzy]')

    parser = OptionParser(option_class=LoadOption, usage=usage, version='%prog 1.0')
    parser.add_option('-l', '--loaders', default=Defaults.LOADERS,
        type='int', dest='LOADERS', metavar='LOADERS',
        help='use LOADERS number of loading processes [default=%default]')
    parser.add_option('-s', '--status', default=Defaults.STATUS,
        type='int', dest='STATUS', metavar='STATUS',
        help='Print status every STATUS files loaded [default=%default]')
    parser.add_option('-b', '--baseuri', default=Defaults.BASEURI,
        dest='BASEURI', metavar='BASEURI',
        help='use BASEURI for any rdf files load [default=%default]')
    parser.add_option('-c', '--catalog', default=Defaults.CATALOG,
        dest='CATALOG', metavar='CATALOG',
        help='CATALOG name on server - use "" for root [default=%default]')
    parser.add_option('-r', '--repository', default=Defaults.REPOSITORY,
        dest='REPOSITORY', metavar='REPOSITORY',
        help='REPOSITORY name in the CATALOG [default=%default]')
    parser.add_option('-C', '--create', default=Defaults.CREATE,
        dest='CREATE', metavar='CREATE', action='store_true',
        help='(Re)CREATE the repository instead of OPENING it [default=open]')
    parser.add_option('-R', '--recurse', default=Defaults.RECURSE,
        dest='RECURSE', metavar='RECURSE', action='store_true',
        help='RECURSE the directories specified [default=do not recurse]')
    parser.add_option('-g', '--graph', default=Defaults.GRAPH,
        dest='GRAPH', metavar='GRAPH',
        help='use the GRAPH string as the graph/context for each file loaded '
            'or use -g "" to indicate the default graph. If -g is not supplied '
            'each file is loaded with the file\'s name string as the graph.')
    parser.add_option('-t', '--timeout', default=Defaults.TIMEOUT,
        type='human_timeout', dest='TIMEOUT', metavar='TIMEOUT',
        help='TIMEOUT for the dedicated loading sessions (e.g. 60s, 10m, 2h) [default=%default]')

    options, args = parser.parse_args()
    OPT = options
    main(args)
